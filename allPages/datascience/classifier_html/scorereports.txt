NAIVE BAYES:
mean accuracy on training data is  0.9567875
Doing cross validation on training data:
mean score is  0.7581625
standard deviation is  0.00409231367933
        -44.0529        really sad              76.0000 URL add
        -42.0168        sad day                 75.0000 get 100
        -40.9836        makes sad               75.0000 using URL
        -40.9836        like crap               74.0000 add everyone
        -40.0000        AT_USER lost            74.0000 day using
        -35.9712        3gs                     74.0000 everyone train
        -34.9650        feeling sick            74.0000 followers day
        -33.0033        lost please             74.0000 pay vip
        -33.0033        tummy hurts             74.0000 train pay
        -30.9598        canceled                57.0000 thanks follow
        -28.9855        soo sad                 39.5000 100 followers
        -28.9855        throat hurts            33.0000 youre welcome
        -28.0112        farrah                  28.0000 hey thanks
        -27.0270        passed away             27.0000 thanks ff
        -27.0270        toe                     23.0000 smiles
        -26.5252        hates                   22.3333 AT_USER congrats
        -25.0000        wishing could           22.0000 always good
        -23.3100        gutted                  21.5000 welcome twitter
        -22.9885        going miss              21.0000 joined twitter
        -21.9780        iphone 3gs              20.0000 blessed
score on test data is  0.807799442897
classification report is
             precision    recall  f1-score   support

          0       0.82      0.79      0.80       177
          1       0.80      0.83      0.81       182

avg / total       0.81      0.81      0.81       359

confusion matrix is  

            predicted class
                  0   1

             0 [139  38]
actual class
             1 [ 31 151]

Area under the ROC curve : 0.888651



sifier.py -train ../../data/training.csv -test ../../data/test.csv -c=log -top=20

mean accuracy on training data is  0.9770125
Doing cross validation on training data:
mean score is  0.770275
standard deviation is  0.00341037021451
        -3.5373 sad                     3.3552  cant wait
        -2.7838 misses                  2.7903  wish luck
        -2.7255 hates                   2.2290  thank
        -2.7197 lonely                  2.2248  welcome
        -2.5822 cancelled               1.9765  proud
        -2.5720 headache                1.9315  yayy
        -2.5536 hurts                   1.8863  dont miss
        -2.5416 missing                 1.8794  wasnt bad
        -2.5157 sucks                   1.8473  chillin
        -2.4896 miss                    1.8228  cannot wait
        -2.4468 unfortunately           1.8152  dont sad
        -2.4436 died                    1.8128  smile
        -2.3872 sadly                   1.7574  cute
        -2.3346 sick                    1.7522  dont need
        -2.3323 bummed                  1.7182  congratulations
        -2.3262 disappointed            1.7111  congrats
        -2.2786 depressing              1.6997  nothing wrong
        -2.2603 gutted                  1.6874  blessed
        -2.2123 bummer                  1.6183  day gone
        -2.2064 poor                    1.6142  yay
score on test data is  0.813370473538
classification report is
             precision    recall  f1-score   support

          0       0.85      0.76      0.80       177
          1       0.79      0.87      0.83       182

avg / total       0.82      0.81      0.81       359

confusion matrix is  [[134  43]
 [ 24 158]]
Area under the ROC curve : 0.891786


SVM
sifier.py -train ../../data/training.csv -test ../../data/test.csv -c=svm -top=20
mean accuracy on training data is  0.994
Doing cross validation on training data:
mean score is  0.75665
standard deviation is  0.00510906057901
        -1.3939 night yes               1.4227  wish luck
        -1.2901 thx babe                1.3264  could hate
        -1.2588 thank mommy             1.3243  sleep talk
        -1.2431 agreed lol              1.3085  says really
        -1.2274 moving thank            1.2975  think alone
        -1.2134 know talking            1.2766  oh sad
        -1.2133 sad                     1.2765  cant wait
        -1.2132 see love                1.2562  cant fair
        -1.2065 lol ha                  1.2405  aw miss
        -1.2062 much hope               1.2297  nope sorry
        -1.1781 awards work             1.2086  shit dont
        -1.1776 hey ever                1.1996  sorry pity
        -1.1743 info wrong              1.1990  omg want
        -1.1734 worry fun               1.1980  nothing wrong
        -1.1706 u gnite                 1.1970  study dont
        -1.1671 lol send                1.1963  sold car
        -1.1477 get town                1.1924  wrong one
        -1.1375 hey shout               1.1923  hate right
        -1.1336 good bye                1.1875  URL heart
        -1.1319 hates                   1.1807  feel sigh
score on test data is  0.782729805014
classification report is
             precision    recall  f1-score   support

          0       0.82      0.72      0.77       177
          1       0.75      0.85      0.80       182

avg / total       0.79      0.78      0.78       359

confusion matrix is  [[127  50]
 [ 28 154]]
Predicted probability is  [ 0.64225088  1.80187697  0.45029774 -0.03795946  0.59212914  0.65682759
 -1.43531966 -0.08257671  0.63917685  1.08576871 -0.26150781  0.65812145
  0.53301847 -0.43572403  0.47355019 -1.68997986  0.72214991  0.6232304
  0.35934688  2.70935093  0.86892622 -0.7238063   0.94885817 -0.19016869
  0.8133532   0.29582846  1.1095643   1.46581516  0.37063803  2.31792082
 -0.69826688  0.36930992 -1.33937527 -1.70481122 -0.71176819  0.31334194
 -0.71983237  1.05683042  0.27002214 -1.69113456 -0.51268047 -0.88727149
  0.16915269  0.73324415  0.06665907  0.9477868  -1.42576813  0.71130953
  0.61589304  0.53922431 -1.07034066  0.47611871  0.89841527 -0.19549384
 -0.71884142 -0.23816873  1.40767309  0.57682308  0.05808136  0.64380918
  1.55681646 -0.59047411 -1.30126037 -2.45842239  0.7194763   0.17176263
  1.95550473 -0.75725435  0.08883754  0.03371496 -0.16267364  0.0238441
 -0.72075675 -0.21434972 -1.47444851  0.03498997 -1.87064851 -1.31435765
 -1.38518021 -2.34920158  0.13322974 -2.04274982 -0.09749258  0.92488485
  0.30533421 -0.27359331 -0.87065758 -2.21431574  0.16469595  0.42153844
  0.75057749  1.60352491  0.97155653  1.09739236  0.03613157  0.81939231
  0.90553172  0.18892049  0.48137091  2.2187702   0.72552878 -0.65511292
  0.96822952  0.92340771  2.34268983  1.84694915  1.03735557  0.92721215
  1.79754572  0.62659157  0.38666661  0.35459848 -0.02829482 -1.68054408
 -0.45425196 -3.07835662 -2.01864407 -0.29743204 -0.46917252 -1.07176225
 -0.90393805 -4.298918   -0.58155178 -0.79539908 -2.96069491 -0.0893881
  0.25113673 -1.72201861 -3.72613856 -0.16079482 -1.62958579 -1.11461535
 -0.50250948 -2.33006675 -0.49847835  0.66545158 -1.0049034  -0.57135155
  0.2821969   0.74192526  0.65706921  2.31400766  1.97714994  1.53792862
  0.18544602  0.83820212  0.38782744 -0.95777623 -1.73511879 -0.24537747
 -2.65379763 -0.82976558  0.56041295 -1.11133972 -0.64612336 -0.52682681
 -0.54183648 -0.6922858  -1.47196617 -2.3257372  -0.86853481 -1.36231193
 -0.66113169 -0.19928634 -3.85753301  0.63165099  1.0332553   0.1813091
  1.58684957  0.4187834   0.40440564  1.88752535  0.13591742  2.53092558
  1.59697673  1.3685521   1.07009892  0.22548834  0.5290815   2.26320128
 -0.93492331  0.37289015  0.78088635  1.51471844  0.51675691  0.23517683
  0.74616842  1.57239107  0.97439874  1.00753817 -1.05086162  1.19605336
 -0.12340964  0.87964004  0.58703418  1.12369728  1.16088622  0.32508777
  0.24730477 -1.24598645 -2.17102819  1.03447713  0.63350292  0.36978277
 -0.39268667  1.56390728  0.05903172 -0.3833993  -0.38638314 -0.51516302
  0.84347054 -0.4844187   0.20828361  1.16453125  0.41005283  1.10127914
  0.46103451 -0.00948172 -0.87601848  0.92872332 -0.5951646  -1.63709762
 -1.14562154  0.23309205 -0.82070451  0.1545175  -0.13902877  0.64498567
  0.89653727 -0.9507794  -0.00607926  0.81062287 -0.07210372  1.86352659
 -1.10328954  1.12151229  0.55735567  1.52535468  0.90867376 -0.82325426
  0.14240522 -0.20194111  0.80648417  0.7731322   0.33811046  0.76462052
  1.45804836  0.89609366 -0.22393772 -0.73116638 -0.34555971 -1.98871903
  0.39570804 -0.81096722  0.02659165  0.85539948  0.62262101 -0.6435453
  0.70071698 -0.18736779 -0.42649161 -0.98900109  0.25256507  0.50195817
  1.92308804  1.57757675  0.83693448  0.66735905  0.85004206  0.78484513
  0.71000661  1.50793214  1.59616806  0.08375218  1.5628118   0.99364995
  1.46880882  0.94913544  1.14990262  1.50566788  2.24679733  1.79107787
 -0.74113843  0.69526162 -0.91492758  0.06674352 -0.04069259  0.16711088
  0.6817129   0.47411861  0.20608275 -1.11907551 -1.36903415 -0.96542222
 -0.09201413 -0.22647222  0.35387566 -0.73656204 -1.03514182 -1.62997997
 -0.38955587 -0.96845152 -0.44357314  0.06112893  0.84498538 -0.93731836
 -0.36433843  0.28786479 -0.819506    0.34967954 -1.87015232 -1.34082337
 -0.61198391 -1.30784157  0.32033742 -0.79719127 -0.16812302  1.23312053
  0.0718677  -0.33782951 -1.29030689 -0.50814363  0.9846124   1.13908716
  0.212914   -2.99224422  0.64424597 -0.4476688   0.14626339 -0.3215976
 -0.94829781  0.87096439  0.6292885  -0.20709966 -0.56981304  2.68889591
 -1.73822041  0.77462023 -0.45113448  1.71979572 -0.37423945  1.5874335
  1.40260808  0.94511582 -1.02996303 -0.46722473  0.01378211  0.25388969
 -0.53816714  0.83835172  0.96500797  1.85075716  0.42575583 -0.1431578
 -0.08231395 -1.01834247  0.36643159 -1.47130625 -1.36224174]
